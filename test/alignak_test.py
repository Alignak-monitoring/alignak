#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2015-2018: Alignak team, see AUTHORS.txt file for contributors
#
# This file is part of Alignak.
#
# Alignak is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Alignak is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with Alignak.  If not, see <http://www.gnu.org/licenses/>.

"""
    This file contains classes and utilities for Alignak tests modules
"""

import os
import sys

import signal

import time
import string
import re
import locale

import shutil
import psutil
import subprocess

from copy import deepcopy

import unittest2

import logging
from logging import Handler, Formatter
from logging.handlers import TimedRotatingFileHandler

import requests_mock

import alignak
from alignak.log import setup_logger, ALIGNAK_LOGGER_NAME, ColorStreamHandler, CollectorHandler
from alignak.bin.alignak_environment import AlignakConfigParser
from alignak.objects.config import Config
from alignak.objects.command import Command
from alignak.objects.module import Module

from alignak.dispatcher import Dispatcher
from alignak.scheduler import Scheduler
from alignak.macroresolver import MacroResolver
from alignak.external_command import ExternalCommandManager, ExternalCommand
from alignak.check import Check
from alignak.message import Message
from alignak.misc.serialization import serialize, unserialize
from alignak.objects.arbiterlink import ArbiterLink
from alignak.objects.schedulerlink import SchedulerLink
from alignak.objects.pollerlink import PollerLink
from alignak.objects.reactionnerlink import ReactionnerLink
from alignak.objects.brokerlink import BrokerLink
from alignak.objects.satellitelink import SatelliteLink
from alignak.notification import Notification
from alignak.modulesmanager import ModulesManager
from alignak.basemodule import BaseModule

from alignak.brok import Brok
from alignak.misc.common import DICT_MODATTR

from alignak.daemons.schedulerdaemon import Alignak
from alignak.daemons.brokerdaemon import Broker
from alignak.daemons.arbiterdaemon import Arbiter
from alignak.daemons.receiverdaemon import Receiver

class AlignakTest(unittest2.TestCase):

    if sys.version_info < (2, 7):
        def assertRegex(self, *args, **kwargs):
            return self.assertRegexpMatches(*args, **kwargs)

    def setUp(self):
        """All tests initialization:
        - output test identifier
        - setup test logger
        - track running Alignak daemons
        - output system cpu/memory
        """
        self.my_pid = os.getpid()

        print "\n" + self.id()
        print("-" * 80)
        print("Test current working directory: %s" % (os.getcwd()))

        # Configure Alignak logger with test configuration
        logger_configuration_file = os.path.join(os.getcwd(), './cfg/alignak-logger.json')
        self.former_log_level = None
        setup_logger(logger_configuration_file, log_dir=None, process_name='', log_file='')
        self.logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        self.logger_.info("Test: %s", self.id())

        # To make sure that no running daemon exist
        print("Checking Alignak running daemons...")
        for daemon in ['broker', 'poller', 'reactionner', 'receiver', 'scheduler', 'arbiter']:
            for proc in psutil.process_iter():
                if 'alignak' in proc.name() and daemon in proc.name():
                    assert False, "*** Found a running Alignak daemon: %s" % (proc.name())

        print("System information:")
        perfdatas = []
        cpu_count = psutil.cpu_count()
        perfdatas.append("'cpu_count'=%d" % cpu_count)

        cpu_percents = psutil.cpu_percent(percpu=True)
        cpu = 1
        for percent in cpu_percents:
            perfdatas.append("'cpu_%d_percent'=%.2f%%" % (cpu, percent))
            cpu += 1
        print "-> cpu: %s" % " ".join(perfdatas)

        perfdatas = []
        virtual_memory = psutil.virtual_memory()
        for key in virtual_memory._fields:
            if 'percent' in key:
                perfdatas.append("'mem_percent_used_%s'=%.2f%%"
                                 % (key, getattr(virtual_memory, key)))

        swap_memory = psutil.swap_memory()
        for key in swap_memory._fields:
            if 'percent' in key:
                perfdatas.append("'swap_used_%s'=%.2f%%"
                                 % (key, getattr(swap_memory, key)))

        print "-> memory: %s" % " ".join(perfdatas)
        print ("-" * 80) + "\n"

    def tearDown(self):
        """Test ending:
        - restore initial log level if it got changed
        """
        # Clear Alignak unit tests log list
        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if getattr(handler, '_name', None) == 'unit_tests':
                print("Log handler %s, stored %d logs" % (handler._name, len(handler.collector)))
                handler.collector = []
                # Restore the collector logger log level
                if self.former_log_level:
                    handler.level = self.former_log_level
                break

    def set_debug_log(self):
        """Set the test logger at DEBUG level - useful for some tests that check debug log"""
        # Change the collector logger log level
        print("set_debug_log")
        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if getattr(handler, '_name', None) == 'unit_tests':
                self.former_log_level = handler.level
                handler.setLevel(logging.DEBUG)
                print("Unit tests handler is set at debug!")
                break

    def _files_update(self, files, replacements):
        """Update files content with the defined replacements

        :param files: list of files to parse and replace
        :param replacements: list of values to replace
        :return:
        """
        for filename in files:
            lines = []
            with open(filename) as infile:
                for line in infile:
                    for src, target in replacements.iteritems():
                        line = line.replace(src, target)
                    lines.append(line)
            with open(filename, 'w') as outfile:
                for line in lines:
                    outfile.write(line)

    def _stop_alignak_daemons(self, arbiter_only=True):
        """ Stop the Alignak daemons started formerly

        If some alignak- daemons are still running after the kill, force kill them.

        :return: None
        """

        print("Stopping the daemons...")
        start = time.time()
        if getattr(self, 'procs', None):
            for name, proc in self.procs.items():
                if arbiter_only and name not in ['arbiter-master']:
                    continue
                if proc.pid == self.my_pid:
                    continue
                print("Asking %s (pid=%d) to end..." % (name, proc.pid))
                try:
                    daemon_process = psutil.Process(proc.pid)
                except psutil.NoSuchProcess:
                    print("not existing!")
                    continue
                # children = daemon_process.children(recursive=True)
                daemon_process.terminate()
                try:
                    # The default arbiter / daemons stopping process is 30 seconds graceful ... so
                    # not really compatible with this default delay. The test must update the
                    # default delay or set a shorter delay than the default one
                    daemon_process.wait(10)
                except psutil.TimeoutExpired:
                    print("***** stopping timeout 10 seconds, force-killing the daemon...")
                    daemon_process.kill()
                except psutil.NoSuchProcess:
                    print("not existing!")
                    pass
                print("%s terminated" % (name))
            print("Stopping daemons duration: %d seconds" % (time.time() - start))

        time.sleep(1.0)

        print("Killing remaining processes...")
        for daemon in ['broker', 'poller', 'reactionner', 'receiver', 'scheduler', 'arbiter']:
            for proc in psutil.process_iter():
                if daemon not in proc.name():
                    continue
                if getattr(self, 'my_pid', None) and proc.pid == self.my_pid:
                    continue
                print("- killing %s" % (proc.name()))
                try:
                    daemon_process = psutil.Process(proc.pid)
                except psutil.NoSuchProcess:
                    print("not existing!")
                    continue

                daemon_process.terminate()
                try:
                    daemon_process.wait(10)
                except psutil.TimeoutExpired:
                    print("***** timeout 10 seconds, force-killing the daemon...")
                    daemon_process.kill()

    def _run_alignak_daemons(self, cfg_folder='/tmp', runtime=30,
                             daemons_list=[], spare_daemons=[], piped=False, run_folder='',
                             arbiter_only=True):
        """ Run the Alignak daemons for a passive configuration

        Let the daemons run for the number of seconds defined in the runtime parameter and
        then kill the required daemons (list in the spare_daemons parameter)

        Check that the run daemons did not raised any ERROR log

        :return: None
        """
        # Load and test the configuration
        cfg_folder = os.path.join(os.path.dirname(os.path.abspath(__file__)), cfg_folder)
        if not run_folder:
            run_folder = cfg_folder
        print("Running Alignak daemons, cfg_folder: %s, run_folder: %s" % (cfg_folder, run_folder))

        # Update alignak.ini file to avoid using the alignak:alignak user account
        files = ['%s/alignak.ini' % cfg_folder]
        replacements = {
            'user=alignak': ';user=alignak',
            'group=alignak': ';group=alignak'

        }
        print("Commenting user/group in alignak.ini...")
        self._files_update(files, replacements)

        print("Cleaning pid and log files...")
        for name in daemons_list + ['arbiter-master']:
            # if arbiter_only and name not in ['arbiter-master']:
            #     continue
            if os.path.exists('%s/%s.pid' % (run_folder, name)):
                os.remove('%s/%s.pid' % (run_folder, name))
                print("- removed %s/%s.pid" % (run_folder, name))
            if os.path.exists('%s/%s.log' % (run_folder, name)):
                os.remove('%s/%s.log' % (run_folder, name))
                print("- removed %s/%s.log" % (run_folder, name))

        self._stop_alignak_daemons()

        # Some script comands may exist in the test folder ...
        if os.path.exists(cfg_folder + '/dummy_command.sh'):
            shutil.copy(cfg_folder + '/dummy_command.sh', '/tmp/dummy_command.sh')
        if os.path.exists(cfg_folder + '/check_command.sh'):
            shutil.copy(cfg_folder + '/check_command.sh', '/tmp/check_command.sh')

        print("Launching the daemons...")
        self.procs = {}
        for name in daemons_list + ['arbiter-master']:
            if arbiter_only and name not in ['arbiter-master']:
                continue
            args = ["../alignak/bin/alignak_%s.py" % name.split('-')[0], "-n", name,
                    "-e", "%s/alignak.ini" % cfg_folder]
            if piped:
                self.procs[name] = \
                    subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            else:
                self.procs[name] = subprocess.Popen(args)

            time.sleep(0.1)
            print("- %s launched (pid=%d)" % (name, self.procs[name].pid))

        time.sleep(3)

        print("Testing daemons start")
        for name, proc in self.procs.items():
            ret = proc.poll()
            if ret is not None:
                print("*** %s exited on start!" % (name))
                if os.path.exists("/tmp/alignak.log"):
                    with open("/tmp/alignak.log") as f:
                        for line in f:
                            print("xxx %s" % line)

                if os.path.exists("%s/arbiter-master.log" % cfg_folder):
                    with open("%s/arbiter-master.log" % cfg_folder) as f:
                        for line in f:
                            print("... %s" % line)

                if proc.stdout:
                    for line in iter(proc.stdout.readline, b''):
                        print(">>> " + line.rstrip())
                else:
                    print("No stdout!")
                if proc.stderr:
                    for line in iter(proc.stderr.readline, b''):
                        print(">>> " + line.rstrip())
                else:
                    print("No stderr!")
            assert ret is None, "Daemon %s not started!" % name
            print("%s running (pid=%d)" % (name, self.procs[name].pid))

        # Let the daemons start ...
        time.sleep(3)

        print("Testing pid files and log files...")
        for name in daemons_list + ['arbiter-master']:
            if arbiter_only and name not in ['arbiter-master']:
                continue
            print("- %s for %s" % ('%s/%s.pid' % (run_folder, name), name))
            # Some times pid and log files may not exist ...
            if not os.path.exists('%s/%s.pid' % (run_folder, name)):
                print('%s/%s.pid does not exist!' % (run_folder, name))
            print("- %s for %s" % ('%s/%s.log' % (run_folder, name), name))
            if not os.path.exists('%s/%s.log' % (run_folder, name)):
                print('%s/%s.log does not exist!' % (run_folder, name))

        time.sleep(1)

        # Let the arbiter build and dispatch its configuration
        # Let the schedulers get their configuration and run the first checks
        time.sleep(runtime)

    def _check_daemons_log_for_errors(self, daemons_list, ignored_warnings=[], ignored_errors=[]):
        """
        Check that the daemons all started correctly and that they got their configuration
        ignored_warnings and ignored_errors are lists of strings that make a WARNING or ERROR log
        not to be considered as a warning or error

        :return:
        """
        print("Get information from log files...")
        travis_run = 'TRAVIS' in os.environ
        nb_errors = 0
        nb_warnings = 0
        for daemon in ['arbiter-master'] + daemons_list:
            print("- log /tmp/%s.log" % daemon)
            assert os.path.exists("/tmp/%s.log" % daemon), '/tmp/%s.log does not exist!' % daemon
            daemon_errors = False
            print("-----\n%s log file\n-----\n" % daemon)
            with open('/tmp/%s.log' % daemon) as f:
                for line in f:
                    if 'WARNING: ' in line or daemon_errors:
                        if not travis_run:
                            print(line[:-1])
                        if 'Cannot call the additional groups setting ' not in line \
                                and 'loop exceeded the maximum expected' not in line \
                                and 'ignoring repeated file' not in line:
                            for ignore_line in ignored_warnings:
                                if ignore_line in line:
                                    break
                            else:
                                nb_warnings += 1
                                print("---" + line[:-1])
                            # nb_warnings += 1
                    if 'ERROR: ' in line or 'CRITICAL: ' in line:
                        if not daemon_errors:
                            print(line[:-1])
                        for ignore_line in ignored_errors:
                            if ignore_line in line:
                                break
                        else:
                            nb_errors += 1
                        if nb_errors > 0:
                            daemon_errors = True

        return (nb_errors, nb_warnings)

    def setup_with_file(self, configuration_file, env_file=None, verbose=False, unit_test=True):
        """
        Load alignak with the provided configuration and environment files

        If verbose is True the envirnment loading is printed out on the console.

        If the configuration loading fails, a SystemExit exception is raised to the caller.

        The conf_is_correct property indicates if the configuration loading succeeded or failed.

        The configuration errors property contains a list of the error message that are normally
        logged as ERROR by the arbiter.

        If unit_test is True it will simulate the dispatcher configuration sending
        to the declared satellites in the configuration. Set to False if you intend to run
        real daemons that will receive their configuration!

        :param configuration_file: path + file name of the main configuration file
        :type configuration_file: str
        :param env_file: path + file name of the alignak environment file
        :type env_file: str
        :param verbose: load Alignak environment in verbose mode (defaults True)
        :type verbose: bool
        :return: None
        """
        self.broks = {}

        # Our own satellites lists ...
        self.arbiters = {}
        self.schedulers = {}
        self.brokers = {}
        self.pollers = {}
        self.receivers = {}
        self.reactionners = {}

        # Our own schedulers lists ...
        # Indexed on the scheduler name
        self._schedulers = {}

        # The main arbiter and scheduler daemons
        self._arbiter = None
        self._scheduler_daemon = None
        self._scheduler = None
        self.conf_is_correct = False
        self.configuration_warnings = []
        self.configuration_errors = []

        # This to allow using a reference configuration if needed,
        # and to make some tests easier to set-up
        print("Preparing default configuration...")
        if os.path.exists('/tmp/etc/alignak'):
            shutil.rmtree('/tmp/etc/alignak')

        if os.path.exists('../etc'):
            shutil.copytree('../etc', '/tmp/etc/alignak')
            files = ['/tmp/etc/alignak/alignak.ini']
            replacements = {
                '_dist=/usr/local/': '_dist=/tmp',
                'user=alignak': ';user=alignak',
                'group=alignak': ';group=alignak'

            }
            self._files_update(files, replacements)
        print("Prepared")

        # Initialize the Arbiter with no daemon configuration file
        configuration_dir = os.path.dirname(configuration_file)
        print("Test configuration directory: %s, file: %s"
              % (os.path.abspath(configuration_dir), configuration_file))
        self.env_filename = None
        if env_file is not None:
            self.env_filename = env_file
        else:
            self.env_filename = os.path.join(configuration_dir, 'alignak.ini')
            if os.path.exists(os.path.join(configuration_dir, 'alignak.ini')):
                self.env_filename = os.path.join(configuration_dir, 'alignak.ini')
            elif os.path.exists(os.path.join(os.path.join(configuration_dir, '..'), 'alignak.ini')):
                    self.env_filename = os.path.join(os.path.join(configuration_dir, '..'), 'alignak.ini')
            else:
                print("No Alignak configuration file found for the test: %s!" % self.env_filename)
                raise SystemExit("No Alignak configuration file found for the test!")

        self.env_filename = os.path.abspath(self.env_filename)
        print("Found Alignak environment file: %s" % self.env_filename)

        # Get Alignak environment
        args = {'<cfg_file>': self.env_filename, '--verbose': verbose}
        self.alignak_env = AlignakConfigParser(args)
        self.alignak_env.parse()

        arbiter_cfg = None
        for daemon_section, daemon_cfg in self.alignak_env.get_daemons().items():
            if daemon_cfg['type'] == 'arbiter':
                arbiter_cfg = daemon_cfg

        arbiter_name = 'Default-Arbiter'
        if arbiter_cfg:
            arbiter_name = arbiter_cfg['name']

        # Using default values that are usually provided by the command line parameters
        args = {
            'env_file': self.env_filename,
            'alignak_name': 'alignak-test', 'daemon_name': arbiter_name,
            'monitoring_files': [configuration_file],
        }
        self._arbiter = Arbiter(**args)

        try:
            # Configure the logger
            # self._arbiter.debug = True
            self._arbiter.setup_alignak_logger()

            # Setup our modules manager
            self._arbiter.load_modules_manager()

            # Load and initialize the arbiter configuration
            self._arbiter.load_monitoring_config_file()

            # If this assertion does not match, then there is a bug in the arbiter :)
            self.assertTrue(self._arbiter.conf.conf_is_correct)
            self.conf_is_correct = True
            self.configuration_warnings = self._arbiter.conf.configuration_warnings
            self.configuration_errors = self._arbiter.conf.configuration_errors
        except SystemExit:
            self.configuration_warnings = self._arbiter.conf.configuration_warnings
            self.configuration_errors = self._arbiter.conf.configuration_errors
            self.show_configuration_logs()
            self.show_logs()
            raise

        # Prepare the configuration dispatching
        for arbiter_link in self._arbiter.conf.arbiters:
            if arbiter_link.get_name() == self._arbiter.arbiter_name:
                self._arbiter.link_to_myself = arbiter_link
            assert arbiter_link is not None, "There is no arbiter link in the configuration!"

        if not unit_test:
            return

        # Prepare the configuration dispatching
        self._arbiter.dispatcher = Dispatcher(self._arbiter.conf, self._arbiter.link_to_myself)
        self._arbiter.dispatcher.prepare_dispatch()

        # Create an Arbiter external commands manager in dispatcher mode
        self._arbiter.external_commands_manager = ExternalCommandManager(self._arbiter.conf,
                                                                         'dispatcher',
                                                                         self._arbiter,
                                                                         accept_unknown=True)

        print("All daemons WS: %s" % ["%s:%s" % (link.address, link.port) for link in self._arbiter.dispatcher.all_daemons_links])

        # Simulate the daemons HTTP interface (very simple simulation !)
        with requests_mock.mock() as mr:
            for link in self._arbiter.dispatcher.all_daemons_links:
                mr.get('http://%s:%s/ping' % (link.address, link.port), json='pong')
                mr.get('http://%s:%s/get_running_id' % (link.address, link.port), json=123456.123456)
                mr.get('http://%s:%s/wait_new_conf' % (link.address, link.port), json=True)
                mr.get('http://%s:%s/fill_initial_broks' % (link.address, link.port), json=[])
                mr.get('http://%s:%s/get_managed_configurations' % (link.address, link.port), json={})

            self._arbiter.dispatcher.check_reachable(test=True)
            self._arbiter.dispatcher.check_dispatch()
            print("-----\nConfiguration got dispatched.")

            # Check that all the daemons links got a configuration
            for sat_type in ('arbiters', 'schedulers', 'reactionners',
                             'brokers', 'receivers', 'pollers'):
                if verbose:
                    print("- for %s:" % (sat_type))
                for sat_link in getattr(self._arbiter.dispatcher, sat_type):
                    if verbose:
                        print(" - %s" % (sat_link))
                    pushed_configuration = getattr(sat_link, 'unit_test_pushed_configuration', None)
                    if pushed_configuration:
                        # print("- %s / %s" % (sat_link.name, pushed_configuration))
                        if verbose:
                            print("   pushed configuration, contains:")
                            for key in pushed_configuration:
                                print("   . %s = %s" % (key, pushed_configuration[key]))
                    # Update the test class satellites lists
                    getattr(self, sat_type).update({sat_link.name: pushed_configuration})
                if verbose:
                    print("- my %s: %s" % (sat_type, getattr(self, sat_type).keys()))

            self.eca = None
            # Initialize a Scheduler daemon
            for scheduler in self._arbiter.dispatcher.schedulers:
                print("-----\nGot a scheduler: %s (%s)" % (scheduler.name, scheduler))
                # Simulate the scheduler daemon start
                args = {
                    'env_file': self.env_filename, 'daemon_name': scheduler.name,
                }
                self._scheduler_daemon = Alignak(**args)
                self._scheduler_daemon.load_modules_manager()

                # Simulate the scheduler daemon receiving the configuration from its arbiter
                pushed_configuration = scheduler.unit_test_pushed_configuration
                self._scheduler_daemon.new_conf = pushed_configuration
                self._scheduler_daemon.setup_new_conf()
                assert self._scheduler_daemon.new_conf == {}
                self._schedulers[scheduler.name] = self._scheduler_daemon.sched

                # Store the last scheduler object to get used in some other functions!
                # this is the real scheduler, not the scheduler daemon!
                self._scheduler = self._scheduler_daemon.sched
                self._scheduler.my_daemon = self._scheduler_daemon
                print("Got a default scheduler: %s\n-----" % self._scheduler)

            # Initialize a Broker daemon
            for broker in self._arbiter.dispatcher.brokers:
                print("-----\nGot a broker: %s (%s)" % (broker.name, broker))
                # Simulate the broker daemon start
                args = {
                    'env_file': self.env_filename, 'daemon_name': broker.name,
                }
                self._broker_daemon = Broker(**args)
                self._broker_daemon.load_modules_manager()

                # Simulate the scheduler daemon receiving the configuration from its arbiter
                pushed_configuration = broker.unit_test_pushed_configuration
                self._broker_daemon.new_conf = pushed_configuration
                self._broker_daemon.setup_new_conf()
                assert self._broker_daemon.new_conf == {}
                print("Got a default broker daemon: %s\n-----" % self._broker_daemon)

            # Get my first broker link
            self._main_broker = None
            if self._scheduler.my_daemon.brokers:
                self._main_broker = [b for b in self._scheduler.my_daemon.brokers.values()][0]

            # Initialize a Receiver daemon
            self._receiver = None
            for receiver in self._arbiter.dispatcher.receivers:
                print("-----\nGot a receiver: %s (%s)" % (receiver.name, receiver))
                # Simulate the receiver daemon start
                args = {
                    'env_file': self.env_filename, 'daemon_name': receiver.name,
                }
                self._receiver_daemon = Receiver(**args)
                self._receiver_daemon.load_modules_manager()

                # Simulate the scheduler daemon receiving the configuration from its arbiter
                pushed_configuration = receiver.unit_test_pushed_configuration
                self._receiver_daemon.new_conf = pushed_configuration
                self._receiver_daemon.setup_new_conf()
                assert self._receiver_daemon.new_conf == {}
                self._receiver = receiver
                print("Got a default receiver: %s\n-----" % self._receiver)

                # for scheduler in self._receiver_daemon.schedulers.values():
                #     scheduler.my_daemon = self._receiver_daemon

        self.ecm_mode = 'applyer'

        # Now we create an external commands manager in receiver mode
        self.ecr = None
        if self._receiver:
            self.ecr = ExternalCommandManager(None, 'receiver', self._receiver_daemon,
                                              accept_unknown=True)
            self._receiver.external_commands_manager = self.ecr

        # and an external commands manager in dispatcher mode for the arbiter
        self.ecd = ExternalCommandManager(self._arbiter.conf, 'dispatcher', self._arbiter,
                                          accept_unknown=True)

        self._arbiter.modules_manager.stop_all()
        self._broker_daemon.modules_manager.stop_all()
        self._scheduler_daemon.modules_manager.stop_all()
        self._receiver_daemon.modules_manager.stop_all()

    def fake_check(self, ref, exit_status, output="OK"):
        """
        Simulate a check execution and result
        :param ref: host/service concerned by the check
        :param exit_status: check exit status code (0, 1, ...).
               If set to None, the check is simply scheduled but not "executed"
        :param output: check output (output + perf data)
        :return:
        """

        now = time.time()
        check = ref.schedule(self._scheduler.hosts,
                             self._scheduler.services,
                             self._scheduler.timeperiods,
                             self._scheduler.macromodulations,
                             self._scheduler.checkmodulations,
                             self._scheduler.checks,
                             force=True, force_time=None)
        # now the check is scheduled and we get it in the action queue
        self._scheduler.add(check)  # check is now in sched.checks[]

        # Allows to force check scheduling without setting its status nor output.
        # Useful for manual business rules rescheduling, for instance.
        if exit_status is None:
            return

        # fake execution
        check.check_time = now

        # and lie about when we will launch it because
        # if not, the schedule call for ref
        # will not really reschedule it because there
        # is a valid value in the future
        ref.next_chk = now - 0.5

        # Max plugin output is default to 8192
        check.get_outputs(output, 8192)
        check.exit_status = exit_status
        check.execution_time = 0.001
        check.status = 'waitconsume'

        # Put the check result in the waiting results for the scheduler ...
        self._scheduler.waiting_results.put(check)

    def scheduler_loop(self, count, items, scheduler=None):
        """
        Manage scheduler actions

        :param count: number of loop turns to run
        :type count: int
        :param items: list of list [[object, exist_status, output]]
        :type items: list
        :param scheduler: The scheduler
        :type scheduler: None | object
        :return: None
        """
        if scheduler is None:
            scheduler = self._scheduler

        macroresolver = MacroResolver()
        macroresolver.init(scheduler.my_daemon.sched.pushed_conf)

        for num in range(count):
            # print("Scheduler loop turn: %s" % num)
            for (item, exit_status, output) in items:
                # print("- item checks creation turn: %s" % item)
                if len(item.checks_in_progress) == 0:
                    # A first full scheduler loop turn to create the checks
                    # if they do not yet exist!
                    for i in scheduler.recurrent_works:
                        (name, fun, nb_ticks) = scheduler.recurrent_works[i]
                        if nb_ticks == 1:
                            # print(" . %s ...running." % name)
                            fun()
                        # else:
                        #     print(" . %s ...ignoring, period: %d" % (name, nb_ticks))
                else:
                    print("Check is still in progress for %s" % item)
                self.assertGreater(len(item.checks_in_progress), 0)
                chk = scheduler.checks[item.checks_in_progress[0]]
                chk.set_type_active()
                chk.check_time = time.time()
                chk.wait_time = 0.0001
                chk.last_poll = chk.check_time
                chk.output = output
                chk.exit_status = exit_status
                scheduler.waiting_results.put(chk)

            # print("-----\n- results fetching turn:")
            for i in scheduler.recurrent_works:
                (name, fun, nb_ticks) = scheduler.recurrent_works[i]
                if nb_ticks == 1:
                    # print(" . %s ...running." % name)
                    fun()
                # else:
                #     print(" . %s ...ignoring, period: %d" % (name, nb_ticks))

    def manage_freshness_check(self, count=1, mysched=None):
        """Run the scheduler loop for freshness_check

        :param count: number of scheduler loop turns
        :type count: int
        :param mysched: a specific scheduler to get used
        :type mysched: None | object
        :return: n/a
        """
        checks = []
        for num in range(count):
            for i in self._scheduler.recurrent_works:
                (name, fun, nb_ticks) = self._scheduler.recurrent_works[i]
                if nb_ticks == 1:
                    fun()
                if name == 'check_freshness':
                    checks = sorted(self._scheduler.checks.values(),
                                    key=lambda x: x.creation_time)
                    checks = [chk for chk in checks if chk.freshness_expiry_check]
        return len(checks)

    def manage_external_command(self, external_command, run=True):
        """Manage an external command.

        :return: result of external command resolution
        """
        res = None
        ext_cmd = ExternalCommand(external_command)
        if self.ecm_mode == 'applyer':
            res = None
            self._scheduler.run_external_commands([external_command])
            self.external_command_loop()
        if self.ecm_mode == 'dispatcher':
            res = self.ecd.resolve_command(ext_cmd)
            if res and run:
                self._arbiter.broks = {}
                self._arbiter.add(ext_cmd)
                self._arbiter.push_external_commands_to_schedulers()
        if self.ecm_mode == 'receiver':
            res = self.ecr.resolve_command(ext_cmd)
            if res and run:
                self._receiver_daemon.broks = {}
                self._receiver_daemon.add(ext_cmd)
                # self._receiver_daemon.push_external_commands_to_schedulers()
                # # Our scheduler
                # self._scheduler = self.schedulers['scheduler-master'].sched
                # Give broks to our broker
                for brok in self._receiver_daemon.broks:
                    print("Brok receiver: %s : %s" % (brok, self._receiver_daemon.broks[brok]))
                    self._broker_daemon.external_broks[brok] = self._receiver_daemon.broks[brok]
        return res

    def external_command_loop(self):
        """Execute the scheduler actions for external commands.

        The scheduler is not an ECM 'dispatcher' but an 'applyer' ... so this function is on
        the external command execution side of the problem.

        :return:
        """
        print("Scheduler loop turn:")
        for i in self._scheduler.recurrent_works:
            (name, fun, nb_ticks) = self._scheduler.recurrent_works[i]
            if nb_ticks == 1:
                print(" . %s ...running." % name)
                fun()
            else:
                print(" . %s ...ignoring, period: %d" % (name, nb_ticks))
        self.assert_no_log_match("External command Brok could not be sent to any daemon!")

    def worker_loop(self, verbose=True):
        self._scheduler.delete_zombie_checks()
        self._scheduler.delete_zombie_actions()
        checks = self._scheduler.get_to_run_checks(True, False, worker_name='tester')
        actions = self._scheduler.get_to_run_checks(False, True, worker_name='tester')
        if verbose is True:
            self.show_actions()
        for a in actions:
            a.status = 'inpoller'
            a.check_time = time.time()
            a.exit_status = 0
            self._scheduler.put_results(a)
        if verbose is True:
            self.show_actions()

    def launch_internal_check(self, svc_br):
        """ Launch an internal check for the business rule service provided """
        # Launch an internal check
        now = time.time()
        self._scheduler.add(svc_br.launch_check(now - 1,
                                                self._scheduler.hosts,
                                                self._scheduler.services,
                                                self._scheduler.timeperiods,
                                                self._scheduler.macromodulations,
                                                self._scheduler.checkmodulations,
                                                self._scheduler.checks))
        c = svc_br.actions[0]
        self.assertEqual(True, c.internal)
        self.assertTrue(c.is_launchable(now))

        # ask the scheduler to launch this check
        # and ask 2 loops: one to launch the check
        # and another to get the result
        self.scheduler_loop(2, [])

        # We should not have the check anymore
        self.assertEqual(0, len(svc_br.actions))

    def show_logs(self):
        """Show logs. Get logs collected by the unit tests collector handler and print them"""
        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if isinstance(handler, CollectorHandler):
                print "--- logs <<<----------------------------------"
                for log in handler.collector:
                    self.safe_print(log)
                print "--- logs >>>----------------------------------"
                break
        else:
            assert False, "Alignak test Logger is not initialized correctly!"

    def show_actions(self):
        """"Show the inner actions"""
        macroresolver = MacroResolver()
        macroresolver.init(self._scheduler_daemon.sched.pushed_conf)

        print("--- Scheduler: %s" % self._scheduler.my_daemon.name)
        print("--- actions <<<----------------------------------")
        actions = sorted(self._scheduler.actions.values(), key=lambda x: (x.t_to_go, x.creation_time))
        for action in actions:
            print("Time to launch action: %s, creation: %s, now: %s" % (action.t_to_go, action.creation_time, time.time()))
            if action.is_a == 'notification':
                item = self._scheduler.find_item_by_id(action.ref)
                if item.my_type == "host":
                    ref = "host: %s" % item.get_name()
                else:
                    hst = self._scheduler.find_item_by_id(item.host)
                    ref = "svc: %s/%s" % (hst.get_name(), item.get_name())
                print("NOTIFICATION %s (%s - %s) [%s], created: %s for '%s': %s"
                      % (action.type, action.uuid, action.status, ref,
                         time.asctime(time.localtime(action.t_to_go)),
                         action.contact_name, action.command))
            elif action.is_a == 'eventhandler':
                print "EVENTHANDLER:", action
            else:
                print "ACTION:", action
        print "--- actions >>>----------------------------------"

    def show_checks(self):
        """
        Show checks from the scheduler
        :return:
        """
        print "--- Scheduler: %s" % self._scheduler.my_daemon.name
        print "--- checks <<<--------------------------------"
        checks = sorted(self._scheduler.checks.values(), key=lambda x: x.creation_time)
        for check in checks:
            print("- %s" % check)
        print "--- checks >>>--------------------------------"

    def show_and_clear_actions(self):
        self.show_actions()
        self.clear_actions()

    def count_logs(self):
        """Count the logs collected by the unit tests collector handler and print them"""
        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if isinstance(handler, CollectorHandler):
                return len(handler.collector)
        else:
            assert False, "Alignak test Logger is not initialized correctly!"

    def count_actions(self):
        """
        Count the actions in the scheduler's actions.

        @verified
        :return:
        """
        return len(self._scheduler.actions.values())

    def clear_logs(self):
        """
        Remove all the logs stored in the logs collector

        @verified
        :return:
        """
        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if isinstance(handler, CollectorHandler):
                handler.collector = []
                break
        else:
            assert False, "Alignak test Logger is not initialized correctly!"

    def clear_actions(self):
        """
        Clear the actions in the scheduler's actions.

        @verified
        :return:
        """
        self._scheduler.actions = {}

    def check_monitoring_logs(self, expected_logs, dump=True):
        """
        Get the monitoring_log broks and check that they match with the expected_logs provided

        :param expected_logs: expected monitoring logs
        :param dump: True to print out the monitoring logs
        :return:
        """
        # We got 'monitoring_log' broks for logging to the monitoring logs...
        monitoring_logs = []
        for brok in sorted(self._main_broker.broks.values(), key=lambda x: x.creation_time):
            if brok.type == 'monitoring_log':
                data = unserialize(brok.data)
                monitoring_logs.append((data['level'], data['message']))
        if dump:
            print("Monitoring logs: %s" % monitoring_logs)

        assert len(expected_logs) == len(monitoring_logs), monitoring_logs

        for log_level, log_message in expected_logs:
            assert (log_level, log_message) in monitoring_logs, log_message

    def assert_actions_count(self, number):
        """
        Check the number of actions

        @verified

        :param number: number of actions we must have
        :type number: int
        :return: None
        """
        actions = []
        # I do this because sort take too times
        if number != len(self._scheduler.actions):
            actions = sorted(self._scheduler.actions.values(), key=lambda x: x.creation_time)
        self.assertEqual(number, len(self._scheduler.actions),
                         "Not found expected number of actions:\nactions_logs=[[[\n%s\n]]]" %
                         ('\n'.join('\t%s = creation: %s, is_a: %s, type: %s, status: %s, '
                                    'planned: %s, command: %s' %
                                    (idx, b.creation_time, b.is_a, b.type,
                                     b.status, b.t_to_go, b.command)
                                    for idx, b in enumerate(actions))))

    def assert_actions_match(self, index, pattern, field):
        """
        Check if pattern verified in field(property) name of the action with index in action list

        @verified

        :param index: index in the actions list. If index is -1, all the actions in the list are
        searched for a matching pattern
        :type index: int
        :param pattern: pattern to verify is in the action
        :type pattern: str
        :param field: name of the field (property) of the action
        :type field: str
        :return: None
        """
        regex = re.compile(pattern)
        actions = sorted(self._scheduler.actions.values(), key=lambda x: (x.t_to_go, x.creation_time))
        if index != -1:
            myaction = actions[index]
            self.assertTrue(regex.search(getattr(myaction, field)),
                            "Not found a matching pattern in actions:\n"
                            "index=%s field=%s pattern=%r\n"
                            "action_line=creation: %s, is_a: %s, type: %s, "
                            "status: %s, planned: %s, command: %s" % (
                                index, field, pattern, myaction.creation_time, myaction.is_a,
                                myaction.type, myaction.status, myaction.t_to_go, myaction.command))
            return

        for myaction in actions:
            if regex.search(getattr(myaction, field)):
                return

        self.assertTrue(False,
                        "Not found a matching pattern in actions:\nfield=%s pattern=%r\n" %
                        (field, pattern))

    def assert_log_match(self, pattern, index=None):
        """
        Search if the log with the index number has the pattern in the Arbiter logs.

        If index is None, then all the collected logs are searched for the pattern

        Logs numbering starts from 0 (the oldest stored log line)

        This function assert on the search result. As of it, if no log is found with th search
        criteria an assertion is raised and the test stops on error.

        :param pattern: string to search in log
        :type pattern: str
        :param index: index number
        :type index: int
        :return: None
        """
        self.assertIsNotNone(pattern, "Searched pattern can not be None!")

        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if isinstance(handler, CollectorHandler):
                regex = re.compile(pattern)
                log_num = 0

                found = False
                for log in handler.collector:
                    if index is None:
                        if regex.search(log):
                            found = True
                            break
                    elif index == log_num:
                        if regex.search(log):
                            found = True
                            break
                    log_num += 1

                self.assertTrue(found,
                                "Not found a matching log line in logs:\nindex=%s pattern=%r\n"
                                "logs=[[[\n%s\n]]]"
                                % (index, pattern, '\n'.join('\t%s=%s' % (idx, b.strip())
                                                             for idx, b in
                                                             enumerate(handler.collector))))
                break
        else:
            assert False, "Alignak test Logger is not initialized correctly!"

    def assert_checks_count(self, number):
        """
        Check the number of actions

        @verified

        :param number: number of actions we must have
        :type number: int
        :return: None
        """
        checks = sorted(self._scheduler.checks.values(), key=lambda x: x.creation_time)
        self.assertEqual(number, len(checks),
                         "Not found expected number of checks:\nchecks_logs=[[[\n%s\n]]]" %
                         ('\n'.join('\t%s = creation: %s, is_a: %s, type: %s, status: %s, planned: %s, '
                                    'command: %s' %
                                    (idx, b.creation_time, b.is_a, b.type, b.status, b.t_to_go, b.command)
                                    for idx, b in enumerate(checks))))

    def assert_checks_match(self, index, pattern, field):
        """
        Check if pattern verified in field(property) name of the check with index in check list

        @verified

        :param index: index number of checks list
        :type index: int
        :param pattern: pattern to verify is in the check
        :type pattern: str
        :param field: name of the field (property) of the check
        :type field: str
        :return: None
        """
        regex = re.compile(pattern)
        checks = sorted(self._scheduler.checks.values(), key=lambda x: x.creation_time)
        mycheck = checks[index]
        self.assertTrue(regex.search(getattr(mycheck, field)),
                        "Not found a matching pattern in checks:\nindex=%s field=%s pattern=%r\n"
                        "check_line=creation: %s, is_a: %s, type: %s, status: %s, planned: %s, "
                        "command: %s" % (
                            index, field, pattern, mycheck.creation_time, mycheck.is_a,
                            mycheck.type, mycheck.status, mycheck.t_to_go, mycheck.command))

    def _any_check_match(self, pattern, field, assert_not):
        """
        Search if any check matches the requested pattern

        @verified
        :param pattern:
        :param field to search with pattern:
        :param assert_not:
        :return:
        """
        regex = re.compile(pattern)
        checks = sorted(self._scheduler.checks.values(), key=lambda x: x.creation_time)
        for check in checks:
            if re.search(regex, getattr(check, field)):
                self.assertTrue(not assert_not,
                                "Found check:\nfield=%s pattern=%r\n"
                                "check_line=creation: %s, is_a: %s, type: %s, status: %s, "
                                "planned: %s, command: %s" % (
                                    field, pattern, check.creation_time, check.is_a,
                                    check.type, check.status, check.t_to_go, check.command)
                                )
                return
        self.assertTrue(assert_not, "No matching check found:\n"
                                    "pattern = %r\n" "checks = %r" % (pattern, checks))

    def assert_any_check_match(self, pattern, field):
        """
        Assert if any check matches the pattern

        @verified
        :param pattern:
        :param field to search with pattern:
        :return:
        """
        self._any_check_match(pattern, field, assert_not=False)

    def assert_no_check_match(self, pattern, field):
        """
        Assert if no check matches the pattern

        @verified
        :param pattern:
        :param field to search with pattern:
        :return:
        """
        self._any_check_match(pattern, field, assert_not=True)

    def _any_log_match(self, pattern, assert_not):
        """
        Search if any log in the Arbiter logs matches the requested pattern
        If 'scheduler' is True, then uses the scheduler's broks list.

        @verified
        :param pattern:
        :param assert_not:
        :return:
        """
        self.assertIsNotNone(pattern, "Searched pattern can not be None!")

        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if isinstance(handler, CollectorHandler):
                regex = re.compile(pattern)

                for log in handler.collector:
                    if re.search(regex, log):
                        self.assertTrue(not assert_not,
                                        "Found matching log line, pattern: %r\nlog: %r"
                                        % (pattern, log))
                        break
                else:
                    for log in handler.collector:
                        print(".%s" % log)
                    self.assertTrue(assert_not,
                                    "No matching log line found, pattern: %r\n" % pattern)
                break
        else:
            assert False, "Alignak test Logger is not initialized correctly!"

    def assert_any_log_match(self, pattern):
        """Assert if any of the collected log matches the pattern

        :param pattern:
        :return:
        """
        self._any_log_match(pattern, assert_not=False)

    def assert_no_log_match(self, pattern):
        """Assert if no collected log matches the pattern

        :param pattern:
        :return:
        """
        self._any_log_match(pattern, assert_not=True)

    def _any_brok_match(self, pattern, level, assert_not):
        """
        Search if any brok message in the Scheduler broks matches the requested pattern and
        requested level

        @verified
        :param pattern:
        :param assert_not:
        :return:
        """
        regex = re.compile(pattern)

        my_broker = [b for b in self._scheduler.my_daemon.brokers.values()][0]

        monitoring_logs = []
        print("Broker broks: %s" % my_broker.broks)
        for brok in my_broker.broks.values():
            if brok.type == 'monitoring_log':
                data = unserialize(brok.data)
                monitoring_logs.append((data['level'], data['message']))
                if re.search(regex, data['message']) and (level is None or data['level'] == level):
                    self.assertTrue(not assert_not, "Found matching brok:\n"
                                    "pattern = %r\nbrok message = %r" % (pattern, data['message']))
                    return

        self.assertTrue(assert_not, "No matching brok found:\n"
                                    "pattern = %r\n" "brok message = %r" % (pattern,
                                                                            monitoring_logs))

    def assert_any_brok_match(self, pattern, level=None):
        """
        Search if any brok message in the Scheduler broks matches the requested pattern and
        requested level

        @verified
        :param pattern:
        :param scheduler:
        :return:
        """
        self._any_brok_match(pattern, level, assert_not=False)

    def assert_no_brok_match(self, pattern, level=None):
        """
        Search if no brok message in the Scheduler broks matches the requested pattern and
        requested level

        @verified
        :param pattern:
        :param scheduler:
        :return:
        """
        self._any_brok_match(pattern, level, assert_not=True)

    def get_log_match(self, pattern):
        """Get the collected logs matching the provided pattern"""
        self.assertIsNotNone(pattern, "Searched pattern can not be None!")

        logger_ = logging.getLogger(ALIGNAK_LOGGER_NAME)
        for handler in logger_.handlers:
            if isinstance(handler, CollectorHandler):
                regex = re.compile(pattern)
                res = []
                for log in handler.collector:
                    if re.search(regex, log):
                        res.append(log)
                return res
        else:
            assert False, "Alignak test Logger is not initialized correctly!"

    def show_configuration_logs(self):
        """
        Prints the configuration logs

        @verified
        :return:
        """
        print("Configuration warnings:")
        for msg in self.configuration_warnings:
            print(" - %s" % msg)
        print("Configuration errors:")
        for msg in self.configuration_errors:
            print(" - %s" % msg)

    def _any_cfg_log_match(self, pattern, assert_not):
        """
        Search a pattern in configuration log (warning and error)

        @verified
        :param pattern:
        :return:
        """
        regex = re.compile(pattern)

        cfg_logs = self.configuration_warnings + self.configuration_errors

        for log in cfg_logs:
            if re.search(regex, log):
                self.assertTrue(not assert_not,
                                "Found matching log line:\n"
                                "pattern = %r\nlog = %r" % (pattern, log))
                return

        self.assertTrue(assert_not, "No matching log line found:\n"
                                    "pattern = %r\n" "logs = %r" % (pattern, cfg_logs))

    def assert_any_cfg_log_match(self, pattern):
        """
        Assert if any configuration log matches the pattern

        @verified
        :param pattern:
        :return:
        """
        self._any_cfg_log_match(pattern, assert_not=False)

    def assert_no_cfg_log_match(self, pattern):
        """
        Assert if no configuration log matches the pattern

        @verified
        :param pattern:
        :return:
        """
        self._any_cfg_log_match(pattern, assert_not=True)

    def guess_sys_stdout_encoding(self):
        ''' Return the best guessed encoding to be used for printing on sys.stdout. '''
        return (
               getattr(sys.stdout, 'encoding', None)
            or getattr(sys.__stdout__, 'encoding', None)
            or locale.getpreferredencoding()
            or sys.getdefaultencoding()
            or 'ascii'
        )

    def safe_print(self, *args, **kw):
        """" "print" args to sys.stdout,
        If some of the args aren't unicode then convert them first to unicode,
            using keyword argument 'in_encoding' if provided (else default to UTF8)
            and replacing bad encoded bytes.
        Write to stdout using 'out_encoding' if provided else best guessed encoding,
            doing xmlcharrefreplace on errors.
        """
        in_bytes_encoding = kw.pop('in_encoding', 'UTF-8')
        out_encoding = kw.pop('out_encoding', self.guess_sys_stdout_encoding())
        if kw:
            raise ValueError('unhandled named/keyword argument(s): %r' % kw)
        #
        make_in_data_gen = lambda: ( a if isinstance(a, unicode)
                                    else
                                unicode(str(a), in_bytes_encoding, 'replace')
                            for a in args )

        possible_codings = ( out_encoding, )
        if out_encoding != 'ascii':
            possible_codings += ( 'ascii', )

        for coding in possible_codings:
            data = u' '.join(make_in_data_gen()).encode(coding, 'xmlcharrefreplace')
            try:
                sys.stdout.write(data)
                break
            except UnicodeError as err:
                # there might still have some problem with the underlying sys.stdout.
                # it might be a StringIO whose content could be decoded/encoded in this same process
                # and have encode/decode errors because we could have guessed a bad encoding with it.
                # in such case fallback on 'ascii'
                if coding == 'ascii':
                    raise
                sys.stderr.write('Error on write to sys.stdout with %s encoding: err=%s\nTrying with ascii' % (
                    coding, err))
        sys.stdout.write(b'\n')
